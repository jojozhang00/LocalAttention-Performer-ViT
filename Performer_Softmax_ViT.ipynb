{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQqg20PiDLK0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4cxKCvwnztN"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1l4MdI5kDbnk"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(positions, d_model):\n",
        "\n",
        "    angle_rads = torch.arange(positions, dtype=torch.float32).unsqueeze(1) * torch.pow(10000, -torch.arange(0, d_model, 2, dtype=torch.float32).float() / d_model)\n",
        "    sines = torch.sin(angle_rads)\n",
        "    cosines = torch.cos(angle_rads)\n",
        "\n",
        "    pos_encoding = torch.zeros((positions, d_model), dtype=torch.float32)\n",
        "    pos_encoding[:, 0::2] = sines\n",
        "    pos_encoding[:, 1::2] = cosines\n",
        "\n",
        "    return pos_encoding.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJqnnLjXZJMb"
      },
      "outputs": [],
      "source": [
        "class FastAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, m):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        assert self.d_model == self.head_dim * n_heads, \"d_model must be divisible by n_heads\"\n",
        "\n",
        "        self.scale = math.sqrt(self.head_dim)  # Scaling factor\n",
        "        self.m = m  # Random Features\n",
        "\n",
        "        self.qkv = nn.Linear(d_model, d_model * 3)\n",
        "        self.projection = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Intialize the random matrix for mapping\n",
        "        self.register_buffer(\"R\", torch.randn(self.head_dim, m))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, _ = x.shape\n",
        "        qkv = self.qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = [each.reshape(B, N, self.n_heads, self.head_dim).permute(0, 2, 1, 3) for each in qkv]\n",
        "\n",
        "        q = q * self.scale\n",
        "        k = k * self.scale\n",
        "\n",
        "        # Computing q' and k' using random feature mapping\n",
        "        q_prime = torch.einsum('bnhd,dk->bhkn', q, self.R)\n",
        "        k_prime = torch.einsum('bnhd,dk->bhkn', k, self.R)\n",
        "\n",
        "        k_prime = F.softmax(k_prime, dim=-1)\n",
        "\n",
        "        v_prime = torch.einsum('bhkn,bnhd->bhkd', k_prime, v)\n",
        "        y = torch.einsum('bhkn,bhkd->bnhd', q_prime, v_prime)\n",
        "\n",
        "        y = y.permute(0, 2, 1, 3).reshape(B, N, self.d_model)\n",
        "        y = self.projection(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYMFZXRxDZNE"
      },
      "outputs": [],
      "source": [
        "class MyViT(nn.Module):\n",
        "    def __init__(self, input_shape, n_patches, n_blocks, hidden_d, n_heads, out_d, m_features):\n",
        "        super().__init__()\n",
        "        self.patch_size = (input_shape[1] // n_patches, input_shape[2] // n_patches)\n",
        "        self.d_model = hidden_d\n",
        "        num_pixels_per_patch = self.patch_size[0] * self.patch_size[1] * input_shape[0]\n",
        "        self.embedding = nn.Linear(num_pixels_per_patch, self.d_model)\n",
        "        self.position_embedding = positional_encoding(n_patches * n_patches, self.d_model)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            FastAttention(self.d_model, n_heads, m_features) for _ in range(n_blocks)\n",
        "        ])\n",
        "        self.to_cls_token = nn.Identity()\n",
        "        self.classifier = nn.Linear(self.d_model, out_d)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # Unfold the image into patches\n",
        "        x = x.unfold(2, self.patch_size[0], self.patch_size[0]).unfold(3, self.patch_size[1], self.patch_size[1])\n",
        "        # Flatten the patches\n",
        "        x = x.contiguous().view(B, -1, self.patch_size[0] * self.patch_size[1] * C)\n",
        "        x = self.embedding(x)\n",
        "        x += self.position_embedding.to(x.device)  # Add absolute position embedding\n",
        "        x = self.to_cls_token(x)\n",
        "        # Apply attention blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-354oQkeDrqP"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  # Load data\n",
        "  transform = ToTensor()\n",
        "\n",
        "  train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
        "  test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
        "\n",
        "  train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
        "  test_loader = DataLoader(test_set, shuffle=False, batch_size=32)\n",
        "\n",
        "  # Define model and training options\n",
        "  device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Using device: \", device, f\"{torch.cuda.get_device_name(device)}\" if torch.cuda.is_available() else \"\")\n",
        "  model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10, m_features=128)\n",
        "  model = model.to(device)\n",
        "  N_EPOCHS=10\n",
        "  LR=0.02\n",
        "\n",
        "  # Training loop\n",
        "  optimizer = Adam(model.parameters(), lr=LR)\n",
        "  criterion = CrossEntropyLoss()\n",
        "\n",
        "  train_start_time = time.time()\n",
        "  for epoch in tqdm(range(N_EPOCHS)):\n",
        "    train_loss = 0.0\n",
        "    for x, y in train_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      y_hat = model(x)\n",
        "      loss = criterion(y_hat, y)\n",
        "\n",
        "      train_loss += loss.detach().cpu().item() / len(train_loader)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
        "\n",
        "  epoch_duration = time.time() - train_start_time\n",
        "  print(f\"Training time is: {epoch_duration:.2f} sec\")\n",
        "\n",
        "  # Testing loop\n",
        "  test_start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "    correct, total = 0, 0\n",
        "    test_loss = 0.0\n",
        "    for x, y in tqdm(test_loader, desc=\"Testing\"):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      y_hat = model(x)\n",
        "      loss = criterion(y_hat, y)\n",
        "      test_loss += loss.detach().cpu().item() / len(test_loader)\n",
        "\n",
        "      correct += torch.sum(torch.argmax(y_hat, dim=1)==y).detach().cpu().item()\n",
        "      total += len(x)\n",
        "\n",
        "    print(f\"Test loss: {test_loss:2f}\")\n",
        "    print(f\"Test accuracy: {correct/total*100:.2f}%\")\n",
        "\n",
        "  epoch_duration = time.time() - test_start_time\n",
        "  print(f\"Test time is: {epoch_duration:.2f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYwoP3DTDwTP",
        "outputId": "56c1cf10-65f6-4fa5-a9d5-94067343bf1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device:  cpu \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [02:39<23:52, 159.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 loss: 39.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [05:18<21:13, 159.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 loss: 1.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [07:58<18:36, 159.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 loss: 1.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [10:37<15:56, 159.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 loss: 1.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [13:16<13:16, 159.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 loss: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [15:54<10:35, 158.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 loss: 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [18:33<07:56, 158.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 loss: 0.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [21:12<05:17, 158.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 loss: 0.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [23:51<02:38, 158.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 loss: 0.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [26:29<00:00, 158.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 loss: 0.70\n",
            "Training time is: 1589.82 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 313/313 [00:16<00:00, 18.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.856483\n",
            "Test accuracy: 72.84%\n",
            "Test time is: 16.69 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUuRNPPlDyPG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}